# Playwright MCP Testing Framework

A powerful, AI-driven test automation framework that combines the Model Context Protocol (MCP) with Playwright to enable natural language test creation and execution.

## ğŸš€ Features

- **Natural Language Tests**: Write tests in plain English instead of code
- **AI-Powered Translation**: Uses OpenAI's GPT models to convert natural language to browser actions
- **Comprehensive Error Reporting**: Detailed failure analysis showing expected vs actual results
- **MCP Integration**: Leverages Model Context Protocol for seamless browser automation
- **Multi-Website Support**: Generalized framework that works with any website
- **Smart Element Detection**: Automatic element finding using AI-powered matching
- **Rich Test Reports**: HTML and text reports with screenshots and detailed analytics
- **Flexible Evaluation**: Intelligent test result evaluation with context-aware failure detection

## ğŸ“‹ Prerequisites

- Node.js (v16 or higher)
- OpenAI API key
- Modern web browser (Chrome/Firefox/Safari)

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/innoraft/Playwright-MCP-testing.git
cd Playwright-MCP-testing
```

2. Install dependencies:
```bash
npm install
```

3. Set up your configuration:

Open the configuration file:
```bash
config/llm.config.js
```

Update it with your LLM provider and API key:

```javascript
const llmConfig = {
  provider: 'openai',
  apiKey: "your-api-key-here",
  temperature: 1
};

export default llmConfig;
```

## ğŸ“ Usage

### Basic Test Creation

Create a test file (e.g., `tests/simple-test.test.yml`) with natural language instructions:

```
Navigate to https://example.com
Wait for the page to load
Click on the "Login" button
Enter "testuser" in the username field
Enter "password123" in the password field
Click the "Submit" button
Verify that login was successful by checking for logout link
Take a screenshot of the dashboard
```

### Running Tests

Execute your test with:

```bash
node direct_mcp_stateless.js tests/simple-test.test.yml
```

### Uploading media

If you want to upload any files then at first place them inside the `/mcp-workspace/uploads/` directory
Then use the absolute path to the test step e.g. `- Select the file from the system path '/home/abc/Desktop/playwright-mcp/mcp-workspace/uploads/abc.png'`

### Test Report

After execution, you'll get:
- Detailed console output with step-by-step execution
- HTML report with screenshots and analytics
- Test reports saved in `test-reports/` directory
- Screenshots saved in `/mcp-workspace/test-screenshots/` directory

## ğŸ§ª Example Tests

The framework includes several example tests:

- **Simple Navigation**: Basic website navigation and interaction
- **Drupal Login**: CMS login workflow testing
- **API Demo Navigation**: REST API interface testing
- **Content Creation**: Dynamic content management testing
- **Form Submission**: Complex form interaction testing
- **Responsive Design**: Multi-device testing scenarios

## ğŸ“Š Test Reports

The framework generates comprehensive reports including:

### Summary Statistics
- Total actions executed
- Pass/fail rates
- Execution duration
- Success percentages

### Detailed Action Analysis
- Individual step outcomes
- Execution times
- Error details with expected vs actual results
- Failure reasons and debugging information

### Visual Documentation
- Full-page screenshots at key steps
- Element highlighting
- Before/after comparisons

## ğŸ”§ Configuration

### MCP Configuration (`playwright-mcp.config.json`)

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": ["@modelcontextprotocol/server-playwright"],
      "env": {
        "PLAYWRIGHT_BROWSER": "chromium"
      }
    }
  }
}
```
## ğŸ¯ Advanced Features

### Smart Element Detection

The framework uses AI to intelligently match element descriptions to actual page elements:

```
Click on the "Sign In" button
Enter text in the search box
Select "Option 2" from the dropdown
```

### Flexible Evaluation Logic

Tests can include complex verification logic:

```
Verify the page loaded successfully by checking:
- Page title contains "Dashboard"
- User menu is visible
- No error messages are present
- Loading indicators are gone
```

### Error Recovery

Built-in error handling and recovery mechanisms:
- Automatic retries for transient failures
- Smart waiting for dynamic content
- Fallback element selection strategies

## ğŸš€ Best Practices

### Writing Effective Tests

1. **Be Specific**: Use clear, unambiguous descriptions
   ```
   âœ… Click the "Submit Order" button in the checkout form
   âŒ Click the button
   ```

2. **Include Verification**: Always verify expected outcomes
   ```
   âœ… Verify that the order confirmation page displays with order number
   âŒ Click submit (without verification)
   ```

3. **Use Wait Strategies**: Allow time for dynamic content
   ```
   âœ… Wait for the loading spinner to disappear
   âœ… Wait 3 seconds for animations to complete
   ```

4. **Prefer Stable Selectors**: Use attributes that are less likely to change
  ```
  âœ… Click the button with id "submit-order"
  âœ… Type "john" into the input with placeholder "Username"
  âŒ Click the blue button on the right
  ```

5. **Use Placeholders and Labels When Possible**: These are more reliable than visual descriptions.
  ```
  âœ… Enter "john@example.com" in the input with placeholder "Email"
  âœ… Type "admin" into the field labeled "Username"
  âŒ Type into the first input box
  ```

6. **Avoid Position-Based Targeting**: UI layout can change; avoid relying on order.
  ```
  âŒ Click the second button
  âŒ Select the third input field
  âœ… Click the button with text "Save"
  ```

7. **Use Text Content for Buttons and Links**: Text is more stable than layout or styling.
  ```
  âœ… Click the "Login" button
  âœ… Click the link "Forgot Password"
  âŒ Click the top-right link
  ```

8. **Prefer IDs and Data Attributes When Available**: 
  ```
  âœ… Click the element with id "submitBtn"
  âœ… Click the element with data-test-id "login-submit"
  âŒ Click the green button
  ```
9. **Describe the Field Purpose, Not Its Appearance**:
  ```
  âœ… Enter "12345" in the ZIP code field
  âŒ Enter "12345" in the small box on the left
  ```

10. **Be Explicit About Which Element You Mean When There Are Multiple Matches**:
  ```
  âœ… Click the "Edit" button for the user "John"
  âŒ Click the "Edit" button
  ```

11. **Use Clear Assertion Targets**:
  ```
  âœ… Verify that the text "Order Placed" is visible
  âœ… Verify that the URL contains "/dashboard"
  âŒ Verify the page looks correct
  ```

12. **Avoid Vague Terms**:
  ```
  âŒ Click something
  âŒ Enter some text
  âœ… Click the "Checkout" button
  âœ… Enter "98765" in the ZIP code field
  ```

### Test Organization

- Group related tests in logical directories
- Use descriptive test file names
- Include setup and teardown steps

## ğŸ›¡ï¸ Error Handling

The framework provides detailed error reporting:

### Common Error Types
- **Element Not Found**: When specified elements can't be located
- **Timeout Errors**: When operations exceed time limits
- **Validation Failures**: When test assertions fail
- **Network Issues**: When pages fail to load

### Error Report Example
```
âŒ Action 5: browser_click
   Status: FAILED
   Expected: Button element with text "Submit"
   Actual: Element not found
   Reason: The specified button could not be located on the current page
   Duration: 2043ms
```

## ğŸ” Debugging

### Debug Mode

Enable verbose logging:
```bash
DEBUG=true node direct_mcp_stateless.js tests/my-test.test.yml
```

### Screenshot Analysis

Automatic screenshots are captured at:
- Page navigation events
- Before/after important actions
- When tests fail
- At test completion

### Log Analysis

Check detailed logs in:
- Console output for real-time feedback
- Test reports for historical analysis
- Screenshot files for visual debugging

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

### Development Setup

```bash
# Install development dependencies
npm install --dev

# Run tests
npm test

# Run linting
npm run lint
```

## ğŸ“š API Reference

### Core Functions

- `generateExecutionPlan(testText, testSteps)`: Generates the execution plan by calling LLM
- `runTest(testText, testName)`: PRuns the tools following the plan
- `recordAction({ tool, params, status, assertion, error, duration, screenshot })`: Records the step is passed or failed

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Model Context Protocol](https://modelcontextprotocol.io/) for the MCP specification
- [Playwright](https://playwright.dev/) for browser automation capabilities
- [OpenAI](https://openai.com/) for AI-powered natural language processing
- Contributors and the open-source community

## ğŸ“ Support

- ğŸ“– [Documentation](https://github.com/innoraft/Playwright-MCP-testing/wiki)
- ğŸ› [Issue Tracker](https://github.com/innoraft/Playwright-MCP-testing/issues)
- ğŸ’¬ [Discussions](https://github.com/innoraft/Playwright-MCP-testing/discussions)
- ğŸ“§ [Email Support](mailto:support@innoraft.com)

---

**Made with â¤ï¸ by InnoRaft**